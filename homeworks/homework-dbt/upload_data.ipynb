{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"yellow\" # green, yellow, fhv\n",
    "file_directory = (f'D:/other/project/data-engineering/homeworks/homework-dbt/data/{data}')\n",
    "files = glob.glob(f'{file_directory}/{data}_tripdata_*.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link for yellow taxi : https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2019-01.csv.gz\n",
    "#link for green taxi : https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-01.csv.gz\n",
    "#link for fhv taxi : https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-01.csv.gz\n",
    "\n",
    "month_list = ['01','02','03','04','05','06',\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"]\n",
    "annual_list = ['2019','2020']\n",
    "for j in annual_list: \n",
    "\n",
    "    for i in month_list:\n",
    "\n",
    "        response = requests.get(f'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/{data}/{data}_tripdata_{j}-{i}.csv.gz')\n",
    "        file_path = (f'{file_directory}/{data}_tripdata_{j}-{i}.csv.gz')\n",
    "        \n",
    "        if response.status_code == 200 : \n",
    "\n",
    "            with open(file_path,'wb') as file : \n",
    "                file.write(response.content)\n",
    "        else:\n",
    "            print('unable to download the files successfully')     \n",
    "\n",
    "\n",
    "print(\"All the monthly data are downloaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch: 1, Files: ['D:/other/project/data-engineering/homeworks/homework-dbt/data/yellow\\\\yellow_tripdata_2019-01.csv.gz']\n",
      "Processing batch: 2, Files: ['D:/other/project/data-engineering/homeworks/homework-dbt/data/yellow\\\\yellow_tripdata_2019-02.csv.gz']\n",
      "Processing batch: 3, Files: ['D:/other/project/data-engineering/homeworks/homework-dbt/data/yellow\\\\yellow_tripdata_2019-03.csv.gz']\n",
      "Processing batch: 4, Files: ['D:/other/project/data-engineering/homeworks/homework-dbt/data/yellow\\\\yellow_tripdata_2019-04.csv.gz']\n",
      "Processing batch: 5, Files: ['D:/other/project/data-engineering/homeworks/homework-dbt/data/yellow\\\\yellow_tripdata_2019-05.csv.gz']\n",
      "Processing batch: 6, Files: ['D:/other/project/data-engineering/homeworks/homework-dbt/data/yellow\\\\yellow_tripdata_2019-06.csv.gz']\n",
      "Processing batch: 7, Files: ['D:/other/project/data-engineering/homeworks/homework-dbt/data/yellow\\\\yellow_tripdata_2019-07.csv.gz']\n",
      "Processing batch: 8, Files: ['D:/other/project/data-engineering/homeworks/homework-dbt/data/yellow\\\\yellow_tripdata_2019-08.csv.gz']\n",
      "Processing batch: 9, Files: ['D:/other/project/data-engineering/homeworks/homework-dbt/data/yellow\\\\yellow_tripdata_2019-09.csv.gz']\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "batch_list = []\n",
    "for i in range(0,len(files),batch_size):\n",
    "\n",
    "    batch_files = files[i:i+batch_size]\n",
    "    print(f\"Processing batch: {i // batch_size + 1}, Files: {batch_files}\")\n",
    "    process_file = [pd.read_csv(file,compression='gzip',dtype={'store_and_fwd_flag': 'str'}) for file in batch_files]\n",
    "    merge_df = pd.concat(process_file,ignore_index=True)\n",
    "    batch_list.append(merge_df)\n",
    "\n",
    "final_df = pd.concat(batch_list,ignore_index=True)\n",
    "final_df.to_csv(f\"{file_directory}/{data}_tripdata.csv\",index=False)\n",
    "print(\"Concatenation completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authentication to GCP : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"D:/other/project/data-engineering/homeworks/homework-3/credential.json\"\n",
    "print(os.environ.get(\"GOOGLE_APPLICATION_CREDENTIALS\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to bucket : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client()\n",
    "bucket_name = 'ny-taxi-project-448909-hw-dbt'\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "'''bucket = storage_client.create_bucket(bucket_name)\n",
    "print(f'bucket {bucket_name} was created')'''\n",
    "file_name = (f'{data}_tripdata.csv')\n",
    "directory = (f'{file_directory}/{data}_tripdata.csv')\n",
    "\n",
    "'''for file_name in os.listdir(directory):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(directory,file_name)\n",
    "        blob = bucket.blob(file_name)\n",
    "        blob.upload_from_filename(file_path)\n",
    "        print(f'{file_name} uploaded to {bucket_name}')'''\n",
    "\n",
    "blob = bucket.blob(file_name)\n",
    "blob.upload_from_filename(directory)\n",
    "print(f'{file_name} uploaded to {bucket_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigquery_client = bigquery.Client()\n",
    "dataset_id = f'{bigquery_client.project}.HW_3'\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = 'US'\n",
    "dataset = bigquery_client.create_dataset(dataset)\n",
    "print(f'The {dataset_id} dataset was created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/fhv_tripdata_2019_cleaned.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    f.seek(1876070839)\n",
    "    print(f.readline())  # Print the problematic line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "input_file = \"data/fhv_tripdata_2019_cleaned.csv\"\n",
    "output_file = \"data/fhv_tripdata_2019_fixed.csv\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\", newline='') as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    for row in reader:\n",
    "        # Replace empty fields with explicit empty string\n",
    "        row = ['\"\"' if field == '' else field for field in row]\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"CSV file cleaned and saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
